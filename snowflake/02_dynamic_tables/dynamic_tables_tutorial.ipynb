{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Build Declarative Pipelines using Snowflake Dynamic Tables\n",
        "\n",
        "## Overview\n",
        "\n",
        "This guide demonstrates how to build a declarative incremental pipeline and establish a multi-layered lakehouse architecture in Snowflake using **Dynamic Tables** with native Snowflake tables.\n",
        "\n",
        "Unlike the original tutorial that uses Iceberg tables with external AWS Glue Catalog integration, this simplified version focuses purely on Snowflake's native capabilities, making it easier to get started with declarative data pipelines.\n",
        "\n",
        "### What You Will Learn\n",
        "\n",
        "By the end of this guide, you will learn to:\n",
        "* Create a schema for organizing your data pipeline\n",
        "* Implement Dynamic Tables with automated refresh using TARGET_LAG\n",
        "* Model a multi-layered lakehouse: Bronze (raw data), Silver (cleaned and enhanced data), and Gold (aggregated, analytical data)\n",
        "* Configure incremental refresh modes for efficient data processing\n",
        "* Verify how incremental data inserts into the Bronze layer automatically propagate through the Silver and Gold layers\n",
        "\n",
        "### What You'll Build\n",
        "\n",
        "You will build a three-tiered lakehouse architecture in a single Snowflake schema:\n",
        "* **Bronze Layer**: Raw transactional data stored in regular Snowflake tables\n",
        "* **Silver Layer**: Dynamic Tables that apply cleaning and standardization to Bronze data\n",
        "* **Gold Layer**: Dynamic Tables with denormalized and aggregated data optimized for analytical reporting\n",
        "\n",
        "All layers will reside in: **MASTERCLASS.02_declarative_pipelines**\n",
        "\n",
        "### Prerequisites\n",
        "\n",
        "* A Snowflake account with necessary permissions to create schemas and Dynamic Tables\n",
        "* An existing MASTERCLASS database\n",
        "* An existing warehouse for compute\n",
        "* Basic understanding of SQL\n",
        "* Familiarity with data warehouse concepts\n",
        "\n",
        "### Architecture Diagram\n",
        "\n",
        "```\n",
        "┌──────────────────────────────────────────────────────────────┐\n",
        "│          MASTERCLASS.02_declarative_pipelines                │\n",
        "│                                                              │\n",
        "│  ┌────────────────────────────────────────────────────────┐ │\n",
        "│  │              BRONZE LAYER (Regular Tables)             │ │\n",
        "│  │  de_orders | de_order_items | de_products | de_customers│ │\n",
        "│  └─────────────────────┬──────────────────────────────────┘ │\n",
        "│                        │                                     │\n",
        "│            Dynamic Tables (TARGET_LAG: 1 minute)            │\n",
        "│                        ↓                                     │\n",
        "│  ┌────────────────────────────────────────────────────────┐ │\n",
        "│  │           SILVER LAYER (Dynamic Tables)                │ │\n",
        "│  │      de_orders_cleaned | de_order_items_enriched       │ │\n",
        "│  └─────────────────────┬──────────────────────────────────┘ │\n",
        "│                        │                                     │\n",
        "│            Dynamic Tables (TARGET_LAG: 1 minute)            │\n",
        "│                        ↓                                     │\n",
        "│  ┌────────────────────────────────────────────────────────┐ │\n",
        "│  │            GOLD LAYER (Dynamic Tables)                 │ │\n",
        "│  │         order_summary | sales_summary_trends           │ │\n",
        "│  └────────────────────────────────────────────────────────┘ │\n",
        "└──────────────────────────────────────────────────────────────┘\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Schema Setup\n",
        "\n",
        "In this section, we'll set up the schema for our data pipeline. All Bronze, Silver, and Gold layer tables will reside in the same schema: **MASTERCLASS.02_declarative_pipelines**\n",
        "\n",
        "### Create Schema\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "-- Use the MASTERCLASS database\n",
        "USE DATABASE MASTERCLASS;\n",
        "\n",
        "-- Create the schema for our declarative pipeline\n",
        "CREATE SCHEMA IF NOT EXISTS \"02_declarative_pipelines\";\n",
        "\n",
        "-- Use the schema\n",
        "USE SCHEMA \"02_declarative_pipelines\";\n",
        "\n",
        "-- Verify schema was created\n",
        "SHOW SCHEMAS LIKE '02_declarative_pipelines' IN DATABASE MASTERCLASS;\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Bronze Layer - Raw Data Tables\n",
        "\n",
        "The Bronze layer contains raw, unprocessed data stored in regular Snowflake tables. This layer serves as the foundation for our data pipeline.\n",
        "\n",
        "We'll create four tables:\n",
        "* **de_orders**: Order transaction data\n",
        "* **de_order_items**: Line items for each order\n",
        "* **de_products**: Product dimension data\n",
        "* **de_customers**: Customer dimension data\n",
        "\n",
        "### Create Bronze Layer Tables\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "-- Use MASTERCLASS database and schema\n",
        "USE DATABASE MASTERCLASS;\n",
        "USE SCHEMA \"02_declarative_pipelines\";\n",
        "\n",
        "-- Create de_orders table\n",
        "CREATE OR REPLACE TABLE de_orders (\n",
        "    billing_address STRING,\n",
        "    created_at TIMESTAMP,\n",
        "    currency STRING,\n",
        "    customer_id NUMBER(38,0),\n",
        "    delivery_date TIMESTAMP,\n",
        "    discount_amount FLOAT,\n",
        "    notes STRING,\n",
        "    order_date TIMESTAMP,\n",
        "    order_id NUMBER(38,0),\n",
        "    order_status STRING,\n",
        "    order_uuid STRING,\n",
        "    payment_method STRING,\n",
        "    payment_status STRING,\n",
        "    shipping_address STRING,\n",
        "    shipping_cost FLOAT,\n",
        "    shipping_date TIMESTAMP,\n",
        "    shipping_method STRING,\n",
        "    subtotal FLOAT,\n",
        "    tax_amount FLOAT,\n",
        "    total_amount FLOAT,\n",
        "    updated_at TIMESTAMP\n",
        ");\n",
        "\n",
        "-- Create de_order_items table\n",
        "CREATE OR REPLACE TABLE de_order_items (\n",
        "    created_at TIMESTAMP,\n",
        "    discount_percent NUMBER(38,0),\n",
        "    line_total FLOAT,\n",
        "    order_id NUMBER(38,0),\n",
        "    order_item_id NUMBER(38,0),\n",
        "    product_id NUMBER(38,0),\n",
        "    quantity NUMBER(38,0),\n",
        "    tax_rate FLOAT,\n",
        "    total_price FLOAT,\n",
        "    unit_price FLOAT,\n",
        "    updated_at TIMESTAMP\n",
        ");\n",
        "\n",
        "-- Create de_products table\n",
        "CREATE OR REPLACE TABLE de_products (\n",
        "    barcode STRING,\n",
        "    brand STRING,\n",
        "    category STRING,\n",
        "    color STRING,\n",
        "    cost_price FLOAT,\n",
        "    created_at TIMESTAMP,\n",
        "    description STRING,\n",
        "    dimensions_cm STRING,\n",
        "    is_active BOOLEAN,\n",
        "    launch_date TIMESTAMP,\n",
        "    material STRING,\n",
        "    product_id NUMBER(38,0),\n",
        "    product_name STRING,\n",
        "    product_uuid STRING,\n",
        "    reorder_level NUMBER(38,0),\n",
        "    size STRING,\n",
        "    sku STRING,\n",
        "    stock_quantity NUMBER(38,0),\n",
        "    subcategory STRING,\n",
        "    supplier_id NUMBER(38,0),\n",
        "    unit_price FLOAT,\n",
        "    updated_at TIMESTAMP,\n",
        "    weight_kg FLOAT\n",
        ");\n",
        "\n",
        "-- Create de_customers table\n",
        "CREATE OR REPLACE TABLE de_customers (\n",
        "    address_line1 STRING,\n",
        "    address_line2 STRING,\n",
        "    city STRING,\n",
        "    country STRING,\n",
        "    created_at TIMESTAMP,\n",
        "    customer_id NUMBER(38,0),\n",
        "    customer_segment STRING,\n",
        "    customer_uuid STRING,\n",
        "    date_of_birth TIMESTAMP,\n",
        "    email STRING,\n",
        "    first_name STRING,\n",
        "    gender STRING,\n",
        "    is_active BOOLEAN,\n",
        "    last_login_date TIMESTAMP,\n",
        "    last_name STRING,\n",
        "    phone STRING,\n",
        "    postal_code STRING,\n",
        "    registration_date TIMESTAMP,\n",
        "    state STRING,\n",
        "    total_orders NUMBER(38,0),\n",
        "    total_spent FLOAT,\n",
        "    updated_at TIMESTAMP\n",
        ");\n",
        "\n",
        "-- Verify tables were created\n",
        "SHOW TABLES IN SCHEMA MASTERCLASS.\"02_declarative_pipelines\";\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "-- Insert sample customers\n",
        "INSERT INTO de_customers VALUES\n",
        "('123 Main St', 'Apt 4B', 'New York', 'USA', '2024-01-15 10:00:00', 1001, 'Premium', 'CUST-UUID-1001', '1985-05-15', 'john.doe@email.com', 'John', 'M', TRUE, '2024-12-10', 'Doe', '555-0101', '10001', '2024-01-15', 'NY', 5, 1250.50, '2024-12-10'),\n",
        "('456 Oak Ave', NULL, 'Los Angeles', 'USA', '2024-02-20 11:30:00', 1002, 'Standard', 'CUST-UUID-1002', '1990-08-22', 'jane.smith@email.com', 'Jane', 'F', TRUE, '2024-12-08', 'Smith', '555-0102', '90001', '2024-02-20', 'CA', 3, 890.75, '2024-12-08'),\n",
        "('789 Pine Rd', 'Unit 12', 'Chicago', 'USA', '2024-03-10 14:15:00', 1003, 'Premium', 'CUST-UUID-1003', '1988-11-30', 'bob.johnson@email.com', 'Bob', 'M', TRUE, '2024-12-12', 'Johnson', '555-0103', '60601', '2024-03-10', 'IL', 8, 2150.25, '2024-12-12'),\n",
        "('321 Elm Dr', NULL, 'Houston', 'USA', '2024-04-05 09:45:00', 1004, 'Standard', 'CUST-UUID-1004', '1992-03-18', 'alice.williams@email.com', 'Alice', 'F', TRUE, '2024-12-11', 'Williams', '555-0104', '77001', '2024-04-05', 'TX', 4, 675.90, '2024-12-11'),\n",
        "('654 Maple Ln', 'Suite 200', 'Phoenix', 'USA', '2024-05-12 16:20:00', 1005, 'Premium', 'CUST-UUID-1005', '1987-07-25', 'charlie.brown@email.com', 'Charlie', 'M', TRUE, '2024-12-09', 'Brown', '555-0105', '85001', '2024-05-12', 'AZ', 6, 1580.40, '2024-12-09');\n",
        "\n",
        "-- Insert sample products\n",
        "INSERT INTO de_products VALUES\n",
        "('1234567890123', 'TechBrand', 'Electronics', 'Black', 50.00, '2024-01-01', 'Wireless Mouse', '10x6x4', TRUE, '2024-01-01', 'Plastic', 3001, 'Wireless Mouse Pro', 'PROD-UUID-3001', 10, 'Standard', 'SKU-WM-001', 150, 'Computer Accessories', 2001, 79.99, '2024-12-01', 0.15),\n",
        "('1234567890124', 'TechBrand', 'Electronics', 'Silver', 120.00, '2024-01-05', 'Mechanical Keyboard', '45x15x3', TRUE, '2024-01-05', 'Aluminum', 3002, 'Mechanical Keyboard RGB', 'PROD-UUID-3002', 5, 'Full Size', 'SKU-KB-002', 80, 'Computer Accessories', 2001, 149.99, '2024-12-01', 0.85),\n",
        "('1234567890125', 'HomeBrand', 'Home & Kitchen', 'White', 25.00, '2024-01-10', 'Coffee Maker', '30x20x35', TRUE, '2024-01-10', 'Plastic', 3003, 'Smart Coffee Maker', 'PROD-UUID-3003', 15, 'Large', 'SKU-CM-003', 200, 'Appliances', 2002, 89.99, '2024-12-01', 2.50),\n",
        "('1234567890126', 'SportsBrand', 'Sports & Outdoors', 'Blue', 15.00, '2024-01-15', 'Yoga Mat', '180x60x0.6', TRUE, '2024-01-15', 'Rubber', 3004, 'Premium Yoga Mat', 'PROD-UUID-3004', 20, 'Standard', 'SKU-YM-004', 300, 'Fitness', 2003, 39.99, '2024-12-01', 1.20),\n",
        "('1234567890127', 'FashionBrand', 'Clothing', 'Navy', 30.00, '2024-01-20', 'Cotton T-Shirt', 'M', TRUE, '2024-01-20', 'Cotton', 3005, 'Classic Cotton Tee', 'PROD-UUID-3005', 50, 'M', 'SKU-TS-005', 500, 'Casual Wear', 2004, 29.99, '2024-12-01', 0.20);\n",
        "\n",
        "SELECT 'Loaded ' || COUNT(*) || ' customers' FROM de_customers;\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "-- Insert sample orders\n",
        "INSERT INTO de_orders VALUES\n",
        "('123 Main St, New York, NY 10001', '2024-12-01 10:30:00', 'USD', 1001, '2024-12-05 14:00:00', 0.00, 'First order', '2024-12-01 10:30:00', 5001, 'delivered', 'ORD-2024-5001', 'credit_card', 'paid', '123 Main St, New York, NY 10001', 9.99, '2024-12-02 08:00:00', 'standard', 79.99, 6.40, 96.38, '2024-12-05 14:00:00'),\n",
        "('456 Oak Ave, Los Angeles, CA 90001', '2024-12-02 14:15:00', 'USD', 1002, '2024-12-06 16:30:00', 15.00, 'Express delivery', '2024-12-02 14:15:00', 5002, 'delivered', 'ORD-2024-5002', 'paypal', 'paid', '456 Oak Ave, Los Angeles, CA 90001', 19.99, '2024-12-03 09:00:00', 'express', 149.99, 12.00, 166.98, '2024-12-06 16:30:00'),\n",
        "('789 Pine Rd, Chicago, IL 60601', '2024-12-03 09:45:00', 'USD', 1003, '2024-12-07 11:00:00', 0.00, 'Gift order', '2024-12-03 09:45:00', 5003, 'shipped', 'ORD-2024-5003', 'credit_card', 'paid', '789 Pine Rd, Unit 12, Chicago, IL 60601', 9.99, '2024-12-04 10:00:00', 'standard', 89.99, 7.20, 107.18, '2024-12-04 10:00:00'),\n",
        "('321 Elm Dr, Houston, TX 77001', '2024-12-04 16:20:00', 'USD', 1004, '2024-12-08 12:00:00', 0.00, 'Standard order', '2024-12-04 16:20:00', 5004, 'processing', 'ORD-2024-5004', 'debit_card', 'paid', '321 Elm Dr, Houston, TX 77001', 9.99, '2024-12-05 11:00:00', 'standard', 39.99, 3.20, 53.18, '2024-12-04 16:20:00'),\n",
        "('654 Maple Ln, Phoenix, AZ 85001', '2024-12-05 11:00:00', 'USD', 1005, NULL, 0.00, 'Bulk order', '2024-12-05 11:00:00', 5005, 'confirmed', 'ORD-2024-5005', 'credit_card', 'paid', '654 Maple Ln, Suite 200, Phoenix, AZ 85001', 9.99, NULL, 'standard', 119.96, 9.60, 139.55, '2024-12-05 11:00:00'),\n",
        "('123 Main St, New York, NY 10001', '2024-12-06 13:30:00', 'USD', 1001, '2024-12-10 15:00:00', 10.00, 'Repeat customer discount', '2024-12-06 13:30:00', 5006, 'delivered', 'ORD-2024-5006', 'credit_card', 'paid', '123 Main St, New York, NY 10001', 9.99, '2024-12-07 09:00:00', 'standard', 149.99, 12.00, 161.98, '2024-12-10 15:00:00'),\n",
        "('789 Pine Rd, Chicago, IL 60601', '2024-12-07 10:15:00', 'USD', 1003, '2024-12-11 16:00:00', 0.00, 'Holiday order', '2024-12-07 10:15:00', 5007, 'delivered', 'ORD-2024-5007', 'paypal', 'paid', '789 Pine Rd, Unit 12, Chicago, IL 60601', 9.99, '2024-12-08 08:00:00', 'standard', 69.98, 5.60, 85.57, '2024-12-11 16:00:00'),\n",
        "('456 Oak Ave, Los Angeles, CA 90001', '2024-12-08 15:45:00', 'USD', 1002, '2024-12-12 14:00:00', 0.00, 'Standard order', '2024-12-08 15:45:00', 5008, 'shipped', 'ORD-2024-5008', 'credit_card', 'paid', '456 Oak Ave, Los Angeles, CA 90001', 9.99, '2024-12-09 10:00:00', 'standard', 89.99, 7.20, 107.18, '2024-12-09 10:00:00'),\n",
        "('654 Maple Ln, Phoenix, AZ 85001', '2024-12-09 12:00:00', 'USD', 1005, NULL, 5.00, 'Quick reorder', '2024-12-09 12:00:00', 5009, 'processing', 'ORD-2024-5009', 'debit_card', 'paid', '654 Maple Ln, Suite 200, Phoenix, AZ 85001', 9.99, NULL, 'standard', 79.99, 6.40, 91.38, '2024-12-09 12:00:00'),\n",
        "('321 Elm Dr, Houston, TX 77001', '2024-12-10 09:30:00', 'USD', 1004, NULL, 0.00, 'New order', '2024-12-10 09:30:00', 5010, 'confirmed', 'ORD-2024-5010', 'credit_card', 'pending', '321 Elm Dr, Houston, TX 77001', 9.99, NULL, 'standard', 29.99, 2.40, 42.38, '2024-12-10 09:30:00');\n",
        "\n",
        "-- Insert sample order items\n",
        "INSERT INTO de_order_items VALUES\n",
        "('2024-12-01 10:30:00', 0, 79.99, 5001, 10001, 3001, 1, 0.08, 79.99, 79.99, '2024-12-01 10:30:00'),\n",
        "('2024-12-02 14:15:00', 10, 149.99, 5002, 10002, 3002, 1, 0.08, 134.99, 149.99, '2024-12-02 14:15:00'),\n",
        "('2024-12-03 09:45:00', 0, 89.99, 5003, 10003, 3003, 1, 0.08, 89.99, 89.99, '2024-12-03 09:45:00'),\n",
        "('2024-12-04 16:20:00', 0, 39.99, 5004, 10004, 3004, 1, 0.08, 39.99, 39.99, '2024-12-04 16:20:00'),\n",
        "('2024-12-05 11:00:00', 0, 119.96, 5005, 10005, 3005, 4, 0.08, 119.96, 29.99, '2024-12-05 11:00:00'),\n",
        "('2024-12-06 13:30:00', 0, 149.99, 5006, 10006, 3002, 1, 0.08, 149.99, 149.99, '2024-12-06 13:30:00'),\n",
        "('2024-12-07 10:15:00', 0, 69.98, 5007, 10007, 3004, 2, 0.08, 69.98, 39.99, '2024-12-07 10:15:00'),\n",
        "('2024-12-08 15:45:00', 0, 89.99, 5008, 10008, 3003, 1, 0.08, 89.99, 89.99, '2024-12-08 15:45:00'),\n",
        "('2024-12-09 12:00:00', 0, 79.99, 5009, 10009, 3001, 1, 0.08, 79.99, 79.99, '2024-12-09 12:00:00'),\n",
        "('2024-12-10 09:30:00', 0, 29.99, 5010, 10010, 3005, 1, 0.08, 29.99, 29.99, '2024-12-10 09:30:00');\n",
        "\n",
        "SELECT 'Loaded ' || COUNT(*) || ' orders' FROM de_orders;\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Verify Bronze Layer Data\n",
        "\n",
        "Let's check the row counts in our Bronze layer tables.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "-- Check Bronze layer row counts\n",
        "SELECT 'de_customers' AS table_name, COUNT(*) AS row_count FROM de_customers\n",
        "UNION ALL\n",
        "SELECT 'de_products', COUNT(*) FROM de_products\n",
        "UNION ALL\n",
        "SELECT 'de_orders', COUNT(*) FROM de_orders\n",
        "UNION ALL\n",
        "SELECT 'de_order_items', COUNT(*) FROM de_order_items\n",
        "ORDER BY table_name;\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Silver Layer - Dynamic Tables for Data Transformation\n",
        "\n",
        "The Silver layer uses **Dynamic Tables** to automatically clean, transform, and enrich data from the Bronze layer. Dynamic Tables are declarative - you define the query, and Snowflake handles the refresh automatically.\n",
        "\n",
        "### Key Concepts:\n",
        "* **TARGET_LAG**: Defines how fresh the data should be (e.g., '1 minute' means data will be refreshed within 1 minute of changes)\n",
        "* **REFRESH_MODE**: Can be INCREMENTAL (process only new/changed data) or FULL (reprocess all data)\n",
        "* **WAREHOUSE**: The compute warehouse used for refreshing the dynamic table\n",
        "\n",
        "### Create Silver Layer Dynamic Tables\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "-- Ensure we're using the correct database and schema\n",
        "USE DATABASE MASTERCLASS;\n",
        "USE SCHEMA \"02_declarative_pipelines\";\n",
        "\n",
        "-- Create de_orders_cleaned Dynamic Table\n",
        "-- This table cleans and standardizes orders data\n",
        "CREATE OR REPLACE DYNAMIC TABLE de_orders_cleaned\n",
        "TARGET_LAG = '1 minute'\n",
        "WAREHOUSE = COMPUTE_WH\n",
        "REFRESH_MODE = INCREMENTAL\n",
        "AS\n",
        "SELECT \n",
        "    order_id,\n",
        "    order_uuid,\n",
        "    customer_id,\n",
        "    order_date,\n",
        "    order_status,\n",
        "    UPPER(TRIM(payment_method)) AS payment_method_std,\n",
        "    UPPER(TRIM(payment_status)) AS payment_status_std,\n",
        "    UPPER(TRIM(shipping_method)) AS shipping_method_std,\n",
        "    currency,\n",
        "    subtotal,\n",
        "    discount_amount,\n",
        "    tax_amount,\n",
        "    shipping_cost,\n",
        "    total_amount,\n",
        "    billing_address,\n",
        "    shipping_address,\n",
        "    shipping_date,\n",
        "    delivery_date,\n",
        "    notes,\n",
        "    created_at,\n",
        "    updated_at,\n",
        "    -- Calculated fields\n",
        "    DATEDIFF(day, order_date, shipping_date) AS days_to_ship,\n",
        "    DATEDIFF(day, shipping_date, delivery_date) AS days_to_deliver,\n",
        "    CASE \n",
        "        WHEN order_status = 'delivered' THEN 1\n",
        "        WHEN order_status = 'shipped' THEN 0.75\n",
        "        WHEN order_status = 'processing' THEN 0.5\n",
        "        WHEN order_status = 'confirmed' THEN 0.25\n",
        "        ELSE 0\n",
        "    END AS order_progress_score\n",
        "FROM MASTERCLASS.\"02_declarative_pipelines\".de_orders\n",
        "WHERE order_date IS NOT NULL;\n",
        "\n",
        "-- Verify the dynamic table was created\n",
        "SHOW DYNAMIC TABLES LIKE 'de_orders_cleaned';\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "-- Create de_order_items_enriched Dynamic Table\n",
        "-- This table joins order items with product information\n",
        "CREATE OR REPLACE DYNAMIC TABLE de_order_items_enriched\n",
        "TARGET_LAG = '1 minute'\n",
        "WAREHOUSE = COMPUTE_WH\n",
        "REFRESH_MODE = INCREMENTAL\n",
        "AS\n",
        "SELECT \n",
        "    oi.order_item_id,\n",
        "    oi.order_id,\n",
        "    oi.product_id,\n",
        "    oi.quantity,\n",
        "    oi.unit_price,\n",
        "    oi.discount_percent,\n",
        "    oi.tax_rate,\n",
        "    oi.line_total,\n",
        "    oi.total_price,\n",
        "    -- Product enrichment\n",
        "    p.product_name,\n",
        "    p.sku,\n",
        "    p.brand,\n",
        "    p.category,\n",
        "    p.subcategory,\n",
        "    p.color,\n",
        "    p.size,\n",
        "    p.material,\n",
        "    p.cost_price,\n",
        "    -- Calculated fields\n",
        "    (oi.unit_price - p.cost_price) AS profit_per_unit,\n",
        "    (oi.total_price - (p.cost_price * oi.quantity)) AS profit_per_line,\n",
        "    ROUND((oi.unit_price - p.cost_price) / NULLIF(p.cost_price, 0) * 100, 2) AS profit_margin_percent,\n",
        "    oi.created_at,\n",
        "    oi.updated_at\n",
        "FROM MASTERCLASS.\"02_declarative_pipelines\".de_order_items oi\n",
        "INNER JOIN MASTERCLASS.\"02_declarative_pipelines\".de_products p\n",
        "    ON oi.product_id = p.product_id\n",
        "WHERE oi.order_id IS NOT NULL;\n",
        "\n",
        "-- Verify the dynamic table was created\n",
        "SHOW DYNAMIC TABLES LIKE 'de_order_items_enriched';\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Wait for Initial Refresh and Verify Silver Layer\n",
        "\n",
        "Dynamic Tables refresh automatically based on TARGET_LAG. Let's wait a moment and then check the data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "snowflake-sql"
        }
      },
      "outputs": [],
      "source": [
        "-- Check Silver layer row counts\n",
        "SELECT 'de_orders_cleaned' AS table_name, COUNT(*) AS row_count FROM de_orders_cleaned\n",
        "UNION ALL\n",
        "SELECT 'de_order_items_enriched', COUNT(*) FROM de_order_items_enriched\n",
        "ORDER BY table_name;\n",
        "\n",
        "-- Sample cleaned orders data\n",
        "SELECT * FROM de_orders_cleaned LIMIT 5;\n",
        "\n",
        "-- Sample enriched order items with profit calculations\n",
        "SELECT \n",
        "    order_item_id,\n",
        "    order_id,\n",
        "    product_name,\n",
        "    brand,\n",
        "    category,\n",
        "    quantity,\n",
        "    unit_price,\n",
        "    cost_price,\n",
        "    profit_per_unit,\n",
        "    profit_margin_percent\n",
        "FROM de_order_items_enriched\n",
        "LIMIT 5;\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Gold Layer - Aggregated Analytics with Dynamic Tables\n",
        "\n",
        "The Gold layer contains business-ready, aggregated data optimized for analytics and reporting. These Dynamic Tables join and aggregate data from the Silver layer.\n",
        "\n",
        "### Create Gold Layer Dynamic Tables\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "snowflake-sql"
        }
      },
      "outputs": [],
      "source": [
        "-- Ensure we're using the correct database and schema\n",
        "USE DATABASE MASTERCLASS;\n",
        "USE SCHEMA \"02_declarative_pipelines\";\n",
        "\n",
        "-- Create order_summary Dynamic Table\n",
        "-- This table provides a complete view of each order with customer and item details\n",
        "CREATE OR REPLACE DYNAMIC TABLE order_summary\n",
        "TARGET_LAG = '1 minute'\n",
        "WAREHOUSE = COMPUTE_WH\n",
        "REFRESH_MODE = INCREMENTAL\n",
        "AS\n",
        "SELECT \n",
        "    o.order_id,\n",
        "    o.order_uuid,\n",
        "    o.order_date,\n",
        "    o.order_status,\n",
        "    -- Customer information\n",
        "    c.customer_id,\n",
        "    c.first_name || ' ' || c.last_name AS customer_name,\n",
        "    c.customer_segment,\n",
        "    c.email AS customer_email,\n",
        "    c.city,\n",
        "    c.state,\n",
        "    c.country,\n",
        "    -- Order financials\n",
        "    o.subtotal,\n",
        "    o.discount_amount,\n",
        "    o.tax_amount,\n",
        "    o.shipping_cost,\n",
        "    o.total_amount,\n",
        "    o.payment_method_std AS payment_method,\n",
        "    o.payment_status_std AS payment_status,\n",
        "    -- Shipping details\n",
        "    o.shipping_method_std AS shipping_method,\n",
        "    o.shipping_date,\n",
        "    o.delivery_date,\n",
        "    o.days_to_ship,\n",
        "    o.days_to_deliver,\n",
        "    -- Aggregated order item metrics\n",
        "    COUNT(oi.order_item_id) AS total_items,\n",
        "    SUM(oi.quantity) AS total_quantity,\n",
        "    SUM(oi.profit_per_line) AS total_profit,\n",
        "    ROUND(AVG(oi.profit_margin_percent), 2) AS avg_profit_margin_percent,\n",
        "    -- Order categorization\n",
        "    CASE \n",
        "        WHEN o.total_amount >= 150 THEN 'High Value'\n",
        "        WHEN o.total_amount >= 75 THEN 'Medium Value'\n",
        "        ELSE 'Low Value'\n",
        "    END AS order_value_category,\n",
        "    o.created_at,\n",
        "    o.updated_at\n",
        "FROM MASTERCLASS.\"02_declarative_pipelines\".de_orders_cleaned o\n",
        "INNER JOIN MASTERCLASS.\"02_declarative_pipelines\".de_customers c\n",
        "    ON o.customer_id = c.customer_id\n",
        "LEFT JOIN MASTERCLASS.\"02_declarative_pipelines\".de_order_items_enriched oi\n",
        "    ON o.order_id = oi.order_id\n",
        "GROUP BY \n",
        "    o.order_id, o.order_uuid, o.order_date, o.order_status,\n",
        "    c.customer_id, c.first_name, c.last_name, c.customer_segment,\n",
        "    c.email, c.city, c.state, c.country,\n",
        "    o.subtotal, o.discount_amount, o.tax_amount, o.shipping_cost,\n",
        "    o.total_amount, o.payment_method_std, o.payment_status_std,\n",
        "    o.shipping_method_std, o.shipping_date, o.delivery_date,\n",
        "    o.days_to_ship, o.days_to_deliver,\n",
        "    o.created_at, o.updated_at;\n",
        "\n",
        "-- Verify the dynamic table was created\n",
        "SHOW DYNAMIC TABLES LIKE 'order_summary';\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "snowflake-sql"
        }
      },
      "outputs": [],
      "source": [
        "-- Create sales_summary_trends Dynamic Table\n",
        "-- This table provides time-based sales analytics\n",
        "CREATE OR REPLACE DYNAMIC TABLE sales_summary_trends\n",
        "TARGET_LAG = '1 minute'\n",
        "WAREHOUSE = COMPUTE_WH\n",
        "REFRESH_MODE = INCREMENTAL\n",
        "AS\n",
        "SELECT \n",
        "    DATE_TRUNC('day', o.order_date) AS order_day,\n",
        "    -- Order counts\n",
        "    COUNT(DISTINCT o.order_id) AS total_orders,\n",
        "    COUNT(DISTINCT o.customer_id) AS unique_customers,\n",
        "    -- Revenue metrics\n",
        "    SUM(o.total_amount) AS total_revenue,\n",
        "    SUM(o.subtotal) AS total_subtotal,\n",
        "    SUM(o.discount_amount) AS total_discounts,\n",
        "    SUM(o.tax_amount) AS total_tax,\n",
        "    SUM(o.shipping_cost) AS total_shipping,\n",
        "    AVG(o.total_amount) AS avg_order_value,\n",
        "    -- Profitability metrics\n",
        "    SUM(oi.profit_per_line) AS total_profit,\n",
        "    ROUND(AVG(oi.profit_margin_percent), 2) AS avg_profit_margin,\n",
        "    -- Product metrics\n",
        "    COUNT(DISTINCT oi.product_id) AS unique_products_sold,\n",
        "    SUM(oi.quantity) AS total_units_sold,\n",
        "    -- Category breakdown\n",
        "    COUNT(DISTINCT CASE WHEN oi.category = 'Electronics' THEN oi.order_item_id END) AS electronics_items,\n",
        "    COUNT(DISTINCT CASE WHEN oi.category = 'Home & Kitchen' THEN oi.order_item_id END) AS home_items,\n",
        "    COUNT(DISTINCT CASE WHEN oi.category = 'Sports & Outdoors' THEN oi.order_item_id END) AS sports_items,\n",
        "    COUNT(DISTINCT CASE WHEN oi.category = 'Clothing' THEN oi.order_item_id END) AS clothing_items,\n",
        "    -- Payment method breakdown\n",
        "    COUNT(DISTINCT CASE WHEN o.payment_method_std = 'CREDIT_CARD' THEN o.order_id END) AS credit_card_orders,\n",
        "    COUNT(DISTINCT CASE WHEN o.payment_method_std = 'PAYPAL' THEN o.order_id END) AS paypal_orders,\n",
        "    COUNT(DISTINCT CASE WHEN o.payment_method_std = 'DEBIT_CARD' THEN o.order_id END) AS debit_card_orders,\n",
        "    -- Order status breakdown\n",
        "    COUNT(DISTINCT CASE WHEN o.order_status = 'delivered' THEN o.order_id END) AS delivered_orders,\n",
        "    COUNT(DISTINCT CASE WHEN o.order_status = 'shipped' THEN o.order_id END) AS shipped_orders,\n",
        "    COUNT(DISTINCT CASE WHEN o.order_status = 'processing' THEN o.order_id END) AS processing_orders,\n",
        "    COUNT(DISTINCT CASE WHEN o.order_status = 'confirmed' THEN o.order_id END) AS confirmed_orders\n",
        "FROM MASTERCLASS.\"02_declarative_pipelines\".de_orders_cleaned o\n",
        "LEFT JOIN MASTERCLASS.\"02_declarative_pipelines\".de_order_items_enriched oi\n",
        "    ON o.order_id = oi.order_id\n",
        "GROUP BY DATE_TRUNC('day', o.order_date)\n",
        "ORDER BY order_day;\n",
        "\n",
        "-- Verify the dynamic table was created\n",
        "SHOW DYNAMIC TABLES LIKE 'sales_summary_trends';\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Verify Gold Layer Data\n",
        "\n",
        "Let's check the aggregated data in our Gold layer tables.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "-- Check Gold layer row counts\n",
        "SELECT 'order_summary' AS table_name, COUNT(*) AS row_count FROM order_summary\n",
        "UNION ALL\n",
        "SELECT 'sales_summary_trends', COUNT(*) FROM sales_summary_trends\n",
        "ORDER BY table_name;\n",
        "\n",
        "-- Sample order summary data with profit calculations\n",
        "SELECT \n",
        "    order_id,\n",
        "    order_date,\n",
        "    customer_name,\n",
        "    customer_segment,\n",
        "    total_amount,\n",
        "    total_profit,\n",
        "    avg_profit_margin_percent,\n",
        "    order_value_category,\n",
        "    total_items,\n",
        "    order_status\n",
        "FROM order_summary\n",
        "ORDER BY order_date DESC\n",
        "LIMIT 5;\n",
        "\n",
        "-- Sales trends by day\n",
        "SELECT \n",
        "    order_day,\n",
        "    total_orders,\n",
        "    unique_customers,\n",
        "    total_revenue,\n",
        "    total_profit,\n",
        "    avg_profit_margin,\n",
        "    avg_order_value,\n",
        "    total_units_sold\n",
        "FROM sales_summary_trends\n",
        "ORDER BY order_day DESC;\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Testing Incremental Updates\n",
        "\n",
        "Now let's demonstrate the power of Dynamic Tables by inserting new data into the Bronze layer and observing how it automatically propagates through Silver and Gold layers.\n",
        "\n",
        "### Record Current State\n",
        "\n",
        "First, let's record the current row counts across all layers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "-- Record current state across all layers\n",
        "SELECT 'BRONZE - de_orders' AS layer_table, COUNT(*) AS row_count FROM MASTERCLASS.\"02_declarative_pipelines\".de_orders\n",
        "UNION ALL\n",
        "SELECT 'BRONZE - de_order_items', COUNT(*) FROM MASTERCLASS.\"02_declarative_pipelines\".de_order_items\n",
        "UNION ALL\n",
        "SELECT 'SILVER - de_orders_cleaned', COUNT(*) FROM MASTERCLASS.\"02_declarative_pipelines\".de_orders_cleaned\n",
        "UNION ALL\n",
        "SELECT 'SILVER - de_order_items_enriched', COUNT(*) FROM MASTERCLASS.\"02_declarative_pipelines\".de_order_items_enriched\n",
        "UNION ALL\n",
        "SELECT 'GOLD - order_summary', COUNT(*) FROM MASTERCLASS.\"02_declarative_pipelines\".order_summary\n",
        "UNION ALL\n",
        "SELECT 'GOLD - sales_summary_trends', COUNT(*) FROM MASTERCLASS.\"02_declarative_pipelines\".sales_summary_trends\n",
        "ORDER BY layer_table;\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Insert New Data into Bronze Layer\n",
        "\n",
        "Let's insert 3 new orders with their associated order items to simulate new transactions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "-- Use MASTERCLASS database and schema\n",
        "USE DATABASE MASTERCLASS;\n",
        "USE SCHEMA \"02_declarative_pipelines\";\n",
        "\n",
        "-- Insert 3 new orders\n",
        "INSERT INTO de_orders VALUES\n",
        "('123 Main St, New York, NY 10001', '2024-12-15 10:00:00', 'USD', 1001, NULL, 0.00, 'New test order 1', '2024-12-15 10:00:00', 5011, 'confirmed', 'ORD-2024-5011', 'credit_card', 'paid', '123 Main St, New York, NY 10001', 9.99, NULL, 'standard', 149.99, 12.00, 171.98, '2024-12-15 10:00:00'),\n",
        "('456 Oak Ave, Los Angeles, CA 90001', '2024-12-15 11:30:00', 'USD', 1002, NULL, 20.00, 'New test order 2 with discount', '2024-12-15 11:30:00', 5012, 'processing', 'ORD-2024-5012', 'paypal', 'paid', '456 Oak Ave, Los Angeles, CA 90001', 19.99, NULL, 'express', 299.98, 24.00, 323.97, '2024-12-15 11:30:00'),\n",
        "('789 Pine Rd, Chicago, IL 60601', '2024-12-15 14:15:00', 'USD', 1003, NULL, 0.00, 'New test order 3', '2024-12-15 14:15:00', 5013, 'confirmed', 'ORD-2024-5013', 'credit_card', 'paid', '789 Pine Rd, Unit 12, Chicago, IL 60601', 9.99, NULL, 'standard', 129.98, 10.40, 150.37, '2024-12-15 14:15:00');\n",
        "\n",
        "-- Insert corresponding order items\n",
        "INSERT INTO de_order_items VALUES\n",
        "('2024-12-15 10:00:00', 0, 149.99, 5011, 10011, 3002, 1, 0.08, 149.99, 149.99, '2024-12-15 10:00:00'),\n",
        "('2024-12-15 11:30:00', 10, 149.99, 5012, 10012, 3002, 1, 0.08, 134.99, 149.99, '2024-12-15 11:30:00'),\n",
        "('2024-12-15 11:30:00', 0, 149.99, 5012, 10013, 3002, 1, 0.08, 149.99, 149.99, '2024-12-15 11:30:00'),\n",
        "('2024-12-15 14:15:00', 0, 89.99, 5013, 10014, 3003, 1, 0.08, 89.99, 89.99, '2024-12-15 14:15:00'),\n",
        "('2024-12-15 14:15:00', 0, 39.99, 5013, 10015, 3004, 1, 0.08, 39.99, 39.99, '2024-12-15 14:15:00');\n",
        "\n",
        "SELECT 'Inserted ' || COUNT(*) || ' new orders' AS result\n",
        "FROM de_orders\n",
        "WHERE order_id >= 5011;\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Wait for Dynamic Table Refresh\n",
        "\n",
        "The Dynamic Tables are configured with TARGET_LAG = '1 minute', which means they will automatically refresh within 1 minute of detecting changes in the source tables.\n",
        "\n",
        "**Important**: In a real scenario, you would wait 1-2 minutes for the automatic refresh. For this tutorial, you can either:\n",
        "1. Wait for the automatic refresh (recommended)\n",
        "2. Manually trigger a refresh using `ALTER DYNAMIC TABLE ... REFRESH`\n",
        "\n",
        "Let's manually trigger the refreshes to see immediate results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "-- Manually trigger refresh of Silver layer (optional - would happen automatically)\n",
        "ALTER DYNAMIC TABLE MASTERCLASS.\"02_declarative_pipelines\".de_orders_cleaned REFRESH;\n",
        "ALTER DYNAMIC TABLE MASTERCLASS.\"02_declarative_pipelines\".de_order_items_enriched REFRESH;\n",
        "\n",
        "-- Manually trigger refresh of Gold layer (optional - would happen automatically)\n",
        "ALTER DYNAMIC TABLE MASTERCLASS.\"02_declarative_pipelines\".order_summary REFRESH;\n",
        "ALTER DYNAMIC TABLE MASTERCLASS.\"02_declarative_pipelines\".sales_summary_trends REFRESH;\n",
        "\n",
        "SELECT 'Dynamic tables refreshed' AS status;\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Verify Data Propagation\n",
        "\n",
        "Now let's check that the new data has propagated through all layers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "-- Check updated row counts after incremental insert\n",
        "SELECT 'BRONZE - de_orders' AS layer_table, COUNT(*) AS row_count FROM MASTERCLASS.\"02_declarative_pipelines\".de_orders\n",
        "UNION ALL\n",
        "SELECT 'BRONZE - de_order_items', COUNT(*) FROM MASTERCLASS.\"02_declarative_pipelines\".de_order_items\n",
        "UNION ALL\n",
        "SELECT 'SILVER - de_orders_cleaned', COUNT(*) FROM MASTERCLASS.\"02_declarative_pipelines\".de_orders_cleaned\n",
        "UNION ALL\n",
        "SELECT 'SILVER - de_order_items_enriched', COUNT(*) FROM MASTERCLASS.\"02_declarative_pipelines\".de_order_items_enriched\n",
        "UNION ALL\n",
        "SELECT 'GOLD - order_summary', COUNT(*) FROM MASTERCLASS.\"02_declarative_pipelines\".order_summary\n",
        "UNION ALL\n",
        "SELECT 'GOLD - sales_summary_trends', COUNT(*) FROM MASTERCLASS.\"02_declarative_pipelines\".sales_summary_trends\n",
        "ORDER BY layer_table;\n",
        "\n",
        "-- View the newly added orders in the Gold layer\n",
        "SELECT \n",
        "    order_id,\n",
        "    order_date,\n",
        "    customer_name,\n",
        "    total_amount,\n",
        "    total_profit,\n",
        "    order_value_category,\n",
        "    order_status\n",
        "FROM MASTERCLASS.\"02_declarative_pipelines\".order_summary\n",
        "WHERE order_id >= 5011\n",
        "ORDER BY order_id;\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Monitoring Dynamic Tables\n",
        "\n",
        "Snowflake provides system views to monitor the status and refresh history of Dynamic Tables. Let's explore these monitoring capabilities.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "-- View all Dynamic Tables in the account\n",
        "SHOW DYNAMIC TABLES;\n",
        "\n",
        "-- Get detailed information about Dynamic Tables\n",
        "SELECT \n",
        "    name,\n",
        "    database_name,\n",
        "    schema_name,\n",
        "    target_lag,\n",
        "    refresh_mode,\n",
        "    warehouse,\n",
        "    scheduling_state\n",
        "FROM TABLE(INFORMATION_SCHEMA.DYNAMIC_TABLES())\n",
        "WHERE database_name = 'MASTERCLASS' AND schema_name = '02_declarative_pipelines'\n",
        "ORDER BY name;\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "-- Check refresh history for a specific dynamic table\n",
        "-- This shows when refreshes occurred and how long they took\n",
        "SELECT \n",
        "    name,\n",
        "    refresh_start_time,\n",
        "    refresh_end_time,\n",
        "    DATEDIFF(second, refresh_start_time, refresh_end_time) AS refresh_duration_seconds,\n",
        "    state,\n",
        "    refresh_action\n",
        "FROM TABLE(INFORMATION_SCHEMA.DYNAMIC_TABLE_REFRESH_HISTORY(\n",
        "    NAME => 'MASTERCLASS.\"02_declarative_pipelines\".order_summary'\n",
        "))\n",
        "ORDER BY refresh_start_time DESC\n",
        "LIMIT 10;\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Check Data Freshness\n",
        "\n",
        "Monitor data freshness (lag) for Dynamic Tables to ensure they're meeting their TARGET_LAG commitments.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "-- Check the freshness/lag of Dynamic Tables\n",
        "SELECT \n",
        "    CONCAT(database_name, '.', schema_name, '.', name) AS full_table_name,\n",
        "    target_lag,\n",
        "    data_timestamp,\n",
        "    scheduling_state,\n",
        "    CASE \n",
        "        WHEN scheduling_state = 'RUNNING' THEN 'Actively refreshing'\n",
        "        WHEN scheduling_state = 'SCHEDULED' THEN 'Scheduled for refresh'\n",
        "        ELSE scheduling_state\n",
        "    END AS status_description\n",
        "FROM TABLE(INFORMATION_SCHEMA.DYNAMIC_TABLES())\n",
        "WHERE database_name = 'MASTERCLASS' AND schema_name = '02_declarative_pipelines'\n",
        "ORDER BY name;\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "Congratulations! You've successfully built a complete declarative data pipeline using Snowflake Dynamic Tables.\n",
        "\n",
        "### What You Accomplished\n",
        "\n",
        "In this tutorial, you:\n",
        "\n",
        "1. **Created a Single-Schema Architecture**: Set up MASTERCLASS.\"02_declarative_pipelines\" schema with Bronze (raw), Silver (transformed), and Gold (aggregated) layers\n",
        "2. **Implemented Dynamic Tables**: Created automated data pipelines with TARGET_LAG configuration\n",
        "3. **Configured Incremental Refresh**: Used INCREMENTAL refresh mode for efficient data processing\n",
        "4. **Tested Data Propagation**: Verified that changes in Bronze automatically flow through Silver to Gold\n",
        "5. **Monitored Pipeline Health**: Explored system views to track refresh status and data freshness\n",
        "\n",
        "### Key Benefits of This Approach\n",
        "\n",
        "**Simplicity**: This approach:\n",
        "- Requires no external catalog integration\n",
        "- Eliminates complex S3 permissions and external volumes\n",
        "- Uses only native Snowflake features\n",
        "- Keeps all tables in a single, organized schema\n",
        "\n",
        "**Declarative**: You define WHAT you want (the query), not HOW to maintain it. Snowflake handles:\n",
        "- Automatic refresh scheduling\n",
        "- Incremental processing\n",
        "- Dependency management between layers\n",
        "\n",
        "**Efficiency**: Dynamic Tables with INCREMENTAL mode:\n",
        "- Process only new or changed data\n",
        "- Reduce compute costs\n",
        "- Minimize latency from source to analytics\n",
        "\n",
        "### Best Practices\n",
        "\n",
        "1. **Choose Appropriate TARGET_LAG**: Balance freshness needs with compute costs\n",
        "   - Near real-time: '1 minute' or '5 minutes'\n",
        "   - Standard: '1 hour' or 'DOWNSTREAM'\n",
        "   - Batch: '1 day'\n",
        "\n",
        "2. **Use INCREMENTAL Mode When Possible**: Most efficient for large datasets with incremental changes\n",
        "\n",
        "3. **Monitor Regularly**: Check refresh history and scheduling state to ensure pipelines are healthy\n",
        "\n",
        "4. **Layer Your Data**: Bronze → Silver → Gold pattern provides:\n",
        "   - Separation of concerns\n",
        "   - Easier debugging\n",
        "   - Flexibility to add new analytics\n",
        "   - Clear data lineage\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "- **Experiment with Different TARGET_LAG Values**: See how it affects refresh timing\n",
        "- **Add More Transformations**: Create additional Silver/Gold tables for different business needs\n",
        "- **Implement Alerting**: Use Snowflake's monitoring features to alert on pipeline issues\n",
        "- **Scale Your Data**: Test with larger datasets to see incremental refresh efficiency\n",
        "\n",
        "### Resources\n",
        "\n",
        "- [Snowflake Dynamic Tables Documentation](https://docs.snowflake.com/en/user-guide/dynamic-tables-about)\n",
        "- [Dynamic Tables Best Practices](https://docs.snowflake.com/en/user-guide/dynamic-tables-best-practices)\n",
        "- [Monitoring Dynamic Tables](https://docs.snowflake.com/en/user-guide/dynamic-tables-tasks-manage)\n",
        "\n",
        "---\n",
        "\n",
        "**Thank you for completing this tutorial!** You now have a solid foundation for building declarative data pipelines in Snowflake.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
